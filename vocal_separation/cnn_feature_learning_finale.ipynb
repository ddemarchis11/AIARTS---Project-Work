{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import callbacks, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "zip_drive_path = '/content/drive/MyDrive/mixed_up_data_talk_segmented.zip'\n",
    "\n",
    "zip_local_path = '/content/mixed_up_data_talk_segmented.zip'\n",
    "\n",
    "destination_folder = '/content/datasets/'\n",
    "import os\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "import zipfile\n",
    "with zipfile.ZipFile(zip_local_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/content/datasets/mixed_up_data_talk_segmented\"\n",
    "\n",
    "SR = 16000                # Frequenza di campionamento (Hz)\n",
    "DURATION = 3.0            # Durata di ciascun clip in secondi\n",
    "N_MELS = 128              # Numero di bande Mel\n",
    "N_FFT = 512               # Dimensione finestra FFT\n",
    "HOP_LENGTH = 160          # Hop di 10 ms (160 campioni a 16 kHz)\n",
    "WIN_LENGTH = 400          # Window di 25 ms (400 campioni a 16 kHz)\n",
    "\n",
    "\n",
    "TARGET_FRAMES = int(np.ceil((DURATION * SR - WIN_LENGTH) / HOP_LENGTH)) + 1\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "\n",
    "def load_and_normalize(path, sr=SR, duration=DURATION):\n",
    "    \n",
    "    y, _ = librosa.load(path, sr=sr, duration=duration)\n",
    "    required_length = int(sr * duration)\n",
    "    if len(y) < required_length:\n",
    "        y = np.pad(y, (0, required_length - len(y)))\n",
    "    else:\n",
    "        y = y[:required_length]\n",
    "    max_val = np.max(np.abs(y)) if np.max(np.abs(y)) > 0 else 1.0\n",
    "    y = y / max_val\n",
    "    return y\n",
    "\n",
    "def compute_log_mel_spectrogram(\n",
    "    y,\n",
    "    sr=SR,\n",
    "    n_mels=N_MELS,\n",
    "    n_fft=N_FFT,\n",
    "    hop_length=HOP_LENGTH,\n",
    "    win_length=WIN_LENGTH\n",
    "):\n",
    "\n",
    "    S = librosa.feature.melspectrogram(\n",
    "        y=y,\n",
    "        sr=sr,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        win_length=win_length,\n",
    "        n_mels=n_mels,\n",
    "        power=2.0\n",
    "    )\n",
    "\n",
    "    log_mel_S = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "    if log_mel_S.shape[1] < TARGET_FRAMES:\n",
    "        pad_width = TARGET_FRAMES - log_mel_S.shape[1]\n",
    "        log_mel_S = np.pad(\n",
    "            log_mel_S,\n",
    "            ((0, 0), (0, pad_width)),\n",
    "            mode='constant',\n",
    "            constant_values=log_mel_S.min()\n",
    "        )\n",
    "    else:\n",
    "        log_mel_S = log_mel_S[:, :TARGET_FRAMES]\n",
    "\n",
    "    return log_mel_S\n",
    "\n",
    "class AudioDataset(Sequence):\n",
    "    def __init__(self, file_paths, labels, batch_size=BATCH_SIZE, is_training=True):\n",
    "        \"\"\"\n",
    "        file_paths: lista di percorsi ai file audio\n",
    "        labels: lista di label intere (0 o 1) corrispondenti ai file\n",
    "        \"\"\"\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.is_training = is_training\n",
    "        self.indices = np.arange(len(file_paths))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.file_paths) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.is_training:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "\n",
    "        for i in batch_indices:\n",
    "            file_path = self.file_paths[i]\n",
    "            lbl = self.labels[i]\n",
    "            y = load_and_normalize(file_path)\n",
    "\n",
    "            logmel = compute_log_mel_spectrogram(y)\n",
    "\n",
    "            mean = np.mean(logmel)\n",
    "            std = np.std(logmel) if np.std(logmel) > 0 else 1.0\n",
    "            logmel = (logmel - mean) / std\n",
    "\n",
    "            logmel = logmel[..., np.newaxis]\n",
    "\n",
    "            X_batch.append(logmel)\n",
    "            y_batch.append(lbl)\n",
    "\n",
    "        X_batch = np.array(X_batch, dtype=np.float32)\n",
    "        y_batch = np.array(y_batch, dtype=np.int32)\n",
    "        return X_batch, y_batch\n",
    "\n",
    "def gather_file_paths_and_labels(base_dir):\n",
    "    \n",
    "    file_paths = []\n",
    "    labels = []\n",
    "    for label_dir, label_value in [(\"noisy\", 0), (\"music\", 1)]:\n",
    "        dir_path = os.path.join(base_dir, label_dir)\n",
    "        if not os.path.isdir(dir_path):\n",
    "            continue\n",
    "        for fname in os.listdir(dir_path):\n",
    "            if fname.lower().endswith((\".wav\", \".mp3\", \".flac\")):\n",
    "                full_path = os.path.join(dir_path, fname)\n",
    "                file_paths.append(full_path)\n",
    "                labels.append(label_value)\n",
    "    return file_paths, labels\n",
    "\n",
    "all_files, all_labels = gather_file_paths_and_labels(DATA_DIR)\n",
    "\n",
    "if len(all_files) == 0:\n",
    "    raise ValueError(f\"Nessun file trovato in {DATA_DIR}/noisy e {DATA_DIR}/music\")\n",
    "\n",
    "files_tmp, test_files, labels_tmp, test_labels = train_test_split(\n",
    "    all_files, all_labels,\n",
    "    test_size=0.15,\n",
    "    stratify=all_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_files, valid_files, train_labels, valid_labels = train_test_split(\n",
    "    files_tmp, labels_tmp,\n",
    "    test_size=0.15/0.85,\n",
    "    stratify=labels_tmp,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = AudioDataset(train_files, train_labels, batch_size=BATCH_SIZE, is_training=True)\n",
    "valid_dataset = AudioDataset(valid_files, valid_labels, batch_size=BATCH_SIZE, is_training=False)\n",
    "test_dataset  = AudioDataset(test_files, test_labels, batch_size=BATCH_SIZE, is_training=False)\n",
    "\n",
    "def build_custom_cnn_2d(input_shape=(N_MELS, TARGET_FRAMES, 1), num_classes=2):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same', activation=None)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool2D((2, 2))(x)\n",
    "\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation=None)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool2D((2, 2))(x)\n",
    "\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation=None)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool2D((2, 2))(x)\n",
    "\n",
    "    x = layers.Conv2D(256, (3, 3), padding='same', activation=None)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool2D((2, 2))(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D(name=\"global_average_pooling2d\")(x)\n",
    "\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_custom_cnn_2d()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=8,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    \"best_audio_classifier.h5\",\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss'\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping, reduce_lr, checkpoint]\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "feature_extractor = models.Model(\n",
    "    inputs=model.input,\n",
    "    outputs=model.get_layer(\"global_average_pooling2d\").output\n",
    ")\n",
    "\n",
    "all_test_features = feature_extractor.predict(test_dataset)\n",
    "\n",
    "all_test_labels = np.concatenate(\n",
    "    [y_batch.numpy() for _, y_batch in test_dataset],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "np.save(\"test_features.npy\", all_test_features)\n",
    "np.save(\"test_labels.npy\", all_test_labels)\n",
    "\n",
    "print(\"Estrazione feature completata. File salvati: 'test_features.npy' e 'test_labels.npy'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/domenicodemarchis/Desktop/IAARTS/progettoIAARTS/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Modello caricato da Â«cnn_network.h5Â»\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Modello caricato da Â«\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mÂ»\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 2) Costruisci il dataset di test\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m test_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[1;32m     14\u001b[0m     TEST_DIR,\n\u001b[1;32m     15\u001b[0m     image_size\u001b[38;5;241m=\u001b[39mIMG_SIZE,\n\u001b[1;32m     16\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[1;32m     17\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m            \u001b[38;5;66;03m# niente shuffle: ci serve lâ€™ordine per le metriche\u001b[39;00m\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m class_names \u001b[38;5;241m=\u001b[39m test_ds\u001b[38;5;241m.\u001b[39mclass_names\n\u001b[1;32m     20\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(class_names)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "MODEL_PATH = \"cnn_network.h5\"       # modello salvato\n",
    "TEST_DIR   = \"mixed_up_data_talk_segmented\"            # cartella con il test set\n",
    "IMG_SIZE   = (224, 224)             # dimensione input della rete\n",
    "BATCH_SIZE = 32                     # batch di test\n",
    "\n",
    "model = load_model(MODEL_PATH)\n",
    "print(f\"âœ… Modello caricato da Â«{MODEL_PATH}Â»\")\n",
    "\n",
    "# 2) Costruisci il dataset di test\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    TEST_DIR,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False            # niente shuffle: ci serve lâ€™ordine per le metriche\n",
    ")\n",
    "class_names = test_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(f\"ðŸ”Ž Classi rilevate: {class_names}\")\n",
    "\n",
    "loss, acc = model.evaluate(test_ds, verbose=0)\n",
    "print(f\"\\nðŸ“Š Risultati Test â€” Loss: {loss:.4f}  |  Accuracy: {acc:.2%}\")\n",
    "\n",
    "y_true = np.concatenate([y for _, y in test_ds])\n",
    "y_pred_proba = model.predict(test_ds, verbose=0)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "print(\"\\n=== Classification report ===\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž File di test trovati: 3739\n",
      "âœ… Modello caricato da Â«cnn_network.h5Â»\n",
      "\n",
      "ðŸ“Š Test â€” Loss: 0.0063  |  Accuracy: 99.71%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Valutazione del modello cnn_network.h5 su un test set audio\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "âœ“ Usa le stesse identiche funzioni di preprocessing viste in fase di training\n",
    "âœ“ Calcola loss, accuracy, classification report e matrice di confusione\n",
    "\"\"\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ IMPORT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ COSTANTI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "MODEL_PATH = \"cnn_network.h5\"                          # modello salvato\n",
    "TEST_DIR   = \"mixed_up_data_talk_segmented\"  # root con noisy/ e music/\n",
    "SR          = 16000      # Hz\n",
    "DURATION    = 3.0        # s\n",
    "N_MELS      = 128\n",
    "N_FFT       = 512\n",
    "HOP_LENGTH  = 160        # 10 ms\n",
    "WIN_LENGTH  = 400        # 25 ms\n",
    "TARGET_FRAMES = int(np.ceil((DURATION * SR - WIN_LENGTH) / HOP_LENGTH)) + 1\n",
    "BATCH_SIZE  = 32\n",
    "CLASS_MAP   = {\"noisy\": 0, \"music\": 1}                 # ordine esplicito\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ FUNZIONI DI PREPROCESSING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def load_and_normalize(path, sr=SR, duration=DURATION):\n",
    "    y, _ = librosa.load(path, sr=sr, duration=duration)\n",
    "    required = int(sr * duration)\n",
    "    y = np.pad(y, (0, max(0, required - len(y))))[:required]\n",
    "    max_amp = np.max(np.abs(y)) or 1.0\n",
    "    return y / max_amp\n",
    "\n",
    "def compute_log_mel_spectrogram(y):\n",
    "    S = librosa.feature.melspectrogram(\n",
    "        y=y, sr=SR, n_fft=N_FFT, hop_length=HOP_LENGTH,\n",
    "        win_length=WIN_LENGTH, n_mels=N_MELS, power=2.0\n",
    "    )\n",
    "    log_S = librosa.power_to_db(S, ref=np.max)\n",
    "    # pad / tronca a TARGET_FRAMES\n",
    "    if log_S.shape[1] < TARGET_FRAMES:\n",
    "        pad = TARGET_FRAMES - log_S.shape[1]\n",
    "        log_S = np.pad(log_S, ((0, 0), (0, pad)), mode='constant',\n",
    "                       constant_values=log_S.min())\n",
    "    else:\n",
    "        log_S = log_S[:, :TARGET_FRAMES]\n",
    "    return log_S\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SEQUENCE KERAS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "class AudioDataset(Sequence):\n",
    "    def __init__(self, file_paths, labels, batch_size=BATCH_SIZE):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.file_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idxs = range(idx * self.batch_size,\n",
    "                     min(len(self.file_paths), (idx + 1) * self.batch_size))\n",
    "        X, y = [], []\n",
    "        for i in idxs:\n",
    "            audio = load_and_normalize(self.file_paths[i])\n",
    "            logmel = compute_log_mel_spectrogram(audio)\n",
    "            # z-score clip-wise\n",
    "            mu, sigma = logmel.mean(), logmel.std() or 1.0\n",
    "            logmel = (logmel - mu) / sigma\n",
    "            X.append(logmel[..., np.newaxis])           # â†’ (H, W, 1)\n",
    "            y.append(self.labels[i])\n",
    "        return np.array(X, dtype=np.float32), np.array(y, dtype=np.int32)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ RACCOLTA PERCORSI & LABELS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def gather_files_and_labels(base_dir):\n",
    "    paths, lbls = [], []\n",
    "    for cls_name, cls_idx in CLASS_MAP.items():\n",
    "        cls_dir = os.path.join(base_dir, cls_name)\n",
    "        if not os.path.isdir(cls_dir):\n",
    "            continue\n",
    "        for f in os.listdir(cls_dir):\n",
    "            if f.lower().endswith((\".wav\", \".mp3\", \".flac\")):\n",
    "                paths.append(os.path.join(cls_dir, f))\n",
    "                lbls.append(cls_idx)\n",
    "    return paths, lbls\n",
    "\n",
    "test_files, test_labels = gather_files_and_labels(TEST_DIR)\n",
    "test_dataset = AudioDataset(test_files, test_labels, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"ðŸ”Ž File di test trovati: {len(test_files)}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CARICA & VALUTA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "model = load_model(MODEL_PATH)\n",
    "print(f\"âœ… Modello caricato da Â«{MODEL_PATH}Â»\")\n",
    "\n",
    "loss, acc = model.evaluate(test_dataset, verbose=0)\n",
    "print(f\"\\nðŸ“Š Test â€” Loss: {loss:.4f}  |  Accuracy: {acc:.2%}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ METRICHE DETTAGLIATE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "y_true = np.concatenate([y for _, y in test_dataset])\n",
    "y_pred_prob = model.predict(test_dataset, verbose=1)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "class_names = list(CLASS_MAP.keys())\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
